{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62917 62917\n"
     ]
    }
   ],
   "source": [
    "predictionDB = pd.read_csv(\"../data/processed/predictionDB.csv\",lineterminator='\\n')\n",
    "embeddings = np.load('./../data/processed/embeddings/0003349d47ee039e4600f75f0b7c893aa63e481e.npy')\n",
    "\n",
    "\n",
    "embeddings = [None]*len(predictionDB)\n",
    "i=0\n",
    "for np_name in glob.glob('./../data/processed/embeddings/*.np[yz]'):\n",
    "    embeddings[i] = np.load(np_name)\n",
    "    i = i + 1\n",
    "\n",
    "embeddings\n",
    "print(len(predictionDB),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.0032682128, -0.07904689, -0.03000979, 0.00...\n",
       "1        [0.009278303, 0.059015848, -0.028337339, -0.00...\n",
       "2        [-0.051631384, 0.014555246, -0.052139774, 0.04...\n",
       "3        [0.03008972, 0.024424704, 0.024788633, -0.0183...\n",
       "4        [-0.03437451, 0.054410815, -0.058744326, 0.014...\n",
       "                               ...                        \n",
       "62912    [-0.021051873, 0.00758308, 0.01212802, 0.03859...\n",
       "62913    [-0.06524257, 0.0017218918, -0.079527594, -0.0...\n",
       "62914    [-0.006718385, 0.048148204, -0.07988764, 0.043...\n",
       "62915    [-0.057739496, 0.0742897, 0.019133838, -0.0250...\n",
       "62916    [-0.054419886, -0.0072614155, -0.07316753, -0....\n",
       "Length: 62917, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2 = pd.Series( (v for v in embeddings) )\n",
    "embeddings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#data = embeddings\n",
    "labels = predictionDB[\"inc_complexity\"]\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(embeddings2, labels, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commits_dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(self.X.iloc[index]),torch.as_tensor(self.y.iloc[index]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-3.5666e-02,  2.1958e-02, -3.9789e-02, -6.1809e-03,  6.8587e-02,\n",
      "        -7.5999e-02, -5.8423e-03, -2.8350e-02,  4.5228e-02,  4.2811e-02,\n",
      "         4.8445e-03,  5.7028e-02, -1.8885e-02,  7.1698e-03, -5.3966e-02,\n",
      "        -3.9067e-02, -6.4273e-02,  8.5946e-03, -4.0308e-02,  8.6781e-02,\n",
      "        -1.5623e-01, -4.9236e-02,  1.1501e-01,  1.4198e-02,  2.9187e-02,\n",
      "        -1.8272e-02, -3.0727e-02,  7.7440e-03, -4.8560e-02, -8.0119e-02,\n",
      "         6.4895e-02, -4.4259e-03,  1.1658e-02,  1.3960e-02,  1.9249e-02,\n",
      "         7.9462e-02,  5.7870e-02, -8.3256e-02, -3.9049e-02,  8.4726e-02,\n",
      "        -4.4668e-02,  2.2374e-02,  1.2167e-02, -3.5477e-02, -4.9882e-02,\n",
      "         1.9489e-02,  4.9052e-02, -5.6177e-02,  4.0880e-02,  3.0927e-02,\n",
      "        -6.3145e-02, -4.6525e-02,  6.5082e-02, -5.3560e-02, -5.4483e-03,\n",
      "        -4.4613e-02, -2.2856e-02,  4.4417e-02,  2.7936e-02,  6.1374e-02,\n",
      "         2.0405e-02, -7.4768e-03, -5.2619e-02, -4.5750e-02, -9.3046e-03,\n",
      "         4.2945e-02, -4.9864e-02, -1.3173e-02, -3.5325e-02, -9.6706e-03,\n",
      "         3.4622e-02,  3.0646e-02, -8.5212e-02,  2.2463e-02, -3.3676e-02,\n",
      "         5.1239e-02,  6.1362e-02,  2.7644e-02,  4.9713e-02, -9.8161e-02,\n",
      "         2.0632e-02, -1.6257e-02, -2.5875e-02,  4.9195e-03,  4.5770e-03,\n",
      "         6.4237e-02, -2.6263e-02,  1.9083e-02, -1.2647e-02,  6.4217e-02,\n",
      "         6.8176e-03,  1.6240e-02,  7.5606e-02, -2.7759e-02,  1.6597e-02,\n",
      "        -2.9028e-02,  6.2188e-02,  1.0552e-01,  1.7108e-02,  3.3812e-02,\n",
      "        -1.7156e-02, -2.3429e-02,  6.5548e-02, -1.9831e-02,  6.6305e-02,\n",
      "         5.2452e-02,  4.2667e-02,  9.0969e-02,  1.7505e-02, -7.7034e-02,\n",
      "         2.1668e-02, -9.6665e-02, -5.1108e-02, -5.4302e-02, -3.3473e-03,\n",
      "         9.5897e-02,  2.7226e-04, -3.6028e-02, -5.5863e-02, -1.1077e-02,\n",
      "         3.8327e-02, -6.1376e-02, -5.1857e-02,  1.8442e-02, -1.6075e-02,\n",
      "        -1.8308e-02, -3.7210e-03,  3.1763e-33,  1.1907e-02,  2.7154e-02,\n",
      "        -4.0842e-02,  4.6566e-02,  6.4544e-02, -1.0219e-01, -7.2307e-02,\n",
      "        -1.2700e-01, -3.9694e-02,  1.4473e-03,  1.4712e-02, -9.7716e-02,\n",
      "        -7.0024e-02,  1.6365e-02, -5.2812e-03, -3.7953e-02,  1.4524e-02,\n",
      "        -4.5155e-03, -1.0924e-02, -1.8776e-03, -1.3464e-02, -1.0105e-01,\n",
      "        -4.3756e-02, -6.8146e-02, -1.2200e-02, -4.1684e-03,  6.5592e-02,\n",
      "         6.4725e-02,  9.7907e-03, -3.7761e-02,  4.8362e-02, -4.8752e-02,\n",
      "         8.8177e-02,  4.3280e-02, -1.2046e-02, -2.3853e-02,  3.5881e-02,\n",
      "         3.4011e-02, -9.3298e-02, -8.7896e-03,  3.5431e-02, -8.3977e-03,\n",
      "        -6.9933e-02,  4.2863e-02,  7.6035e-02,  3.8001e-02,  2.2192e-02,\n",
      "        -4.4266e-02,  7.3141e-02,  2.9832e-02,  6.5535e-03,  9.9653e-02,\n",
      "         6.1372e-02,  1.2797e-02, -3.8323e-02,  5.8858e-02, -5.1220e-03,\n",
      "        -2.1281e-02, -4.6880e-02, -2.3796e-02,  4.9167e-03,  1.3040e-03,\n",
      "        -4.5102e-02, -7.8815e-02,  3.1538e-02, -1.5631e-02,  1.7490e-02,\n",
      "         6.9657e-02,  6.1857e-02, -2.8853e-02, -4.7762e-03, -8.8767e-03,\n",
      "         3.3770e-02,  7.1440e-02,  1.0233e-02, -1.4265e-02,  5.3967e-02,\n",
      "         3.5718e-02,  3.0384e-02,  2.6608e-02, -1.0398e-01,  2.1092e-02,\n",
      "         3.2175e-02, -4.6160e-02, -1.7066e-02,  6.5891e-02,  7.6616e-02,\n",
      "         5.6957e-02, -2.8308e-02, -2.7760e-03,  6.8475e-02,  4.3590e-02,\n",
      "         2.3733e-03, -9.1371e-02, -2.9457e-02, -4.5072e-33, -1.9691e-03,\n",
      "        -4.4064e-02, -8.1041e-02,  1.3117e-02, -2.3081e-02,  4.5359e-02,\n",
      "         1.5725e-02,  2.0207e-02,  3.0812e-02, -1.2204e-02,  6.2804e-02,\n",
      "        -9.4994e-03,  3.6841e-02, -2.4916e-02,  4.6569e-02, -2.6516e-02,\n",
      "        -6.0442e-02, -6.6531e-03,  3.9327e-02,  9.8557e-03,  1.0197e-01,\n",
      "         6.2321e-02,  3.9713e-03,  1.2719e-01, -4.0741e-02,  6.4099e-03,\n",
      "        -1.5409e-02,  1.4606e-02, -2.0133e-02,  2.7221e-02,  8.1988e-02,\n",
      "        -1.1628e-02, -2.8250e-02, -2.1342e-02,  7.7672e-02, -8.0594e-02,\n",
      "        -1.2245e-02,  8.3627e-02, -6.4983e-02,  8.7614e-02, -1.9403e-02,\n",
      "        -2.0222e-02,  1.9753e-02,  5.8234e-02, -3.8393e-02, -6.0917e-02,\n",
      "         3.2914e-02,  2.7601e-02, -4.7345e-02,  2.1458e-02,  2.5109e-02,\n",
      "        -4.1348e-02,  4.7825e-02, -3.2457e-03,  9.2435e-02,  1.6174e-02,\n",
      "         1.0610e-02,  1.3990e-01, -9.1394e-02,  4.8774e-02, -2.9232e-02,\n",
      "        -8.7887e-02, -6.5320e-02, -4.7770e-02,  1.5969e-02, -4.2756e-02,\n",
      "        -8.8315e-02, -6.1899e-02,  5.2135e-02, -4.0047e-02, -4.6379e-02,\n",
      "        -2.3707e-02, -9.2395e-03,  4.0527e-03,  5.8612e-02, -1.2316e-01,\n",
      "         4.2969e-02,  6.9175e-02,  6.6303e-02,  5.1972e-02, -2.4566e-02,\n",
      "         1.7748e-02, -2.6151e-02,  2.8974e-02,  5.9853e-02,  3.0803e-02,\n",
      "        -6.3497e-03,  3.5322e-02, -5.4859e-02,  2.4976e-03,  2.4143e-02,\n",
      "        -3.2567e-02,  6.1139e-02, -2.3848e-04,  1.4246e-02, -4.1220e-08,\n",
      "        -4.0381e-02,  7.4778e-02, -6.2371e-02, -3.2520e-02,  8.9382e-02,\n",
      "        -5.5788e-02, -9.7557e-03, -5.3497e-02, -7.2571e-02, -5.8953e-02,\n",
      "        -8.7995e-02,  1.2716e-01, -3.7035e-02,  2.0480e-02, -4.1125e-02,\n",
      "        -8.5227e-02, -6.3779e-02,  1.1639e-01, -4.3136e-02, -3.2992e-02,\n",
      "        -4.6765e-02,  9.1048e-03, -4.9336e-02,  4.9552e-02, -2.1707e-02,\n",
      "         2.8503e-02,  6.6990e-03,  3.1016e-02, -1.8396e-02, -2.9911e-02,\n",
      "         3.5899e-03,  4.7993e-02, -9.5171e-02, -1.6574e-01, -9.2502e-03,\n",
      "         1.4426e-02,  5.8110e-02,  5.2588e-03,  3.4343e-02,  4.3763e-02,\n",
      "         5.2546e-04, -3.0417e-02,  2.9623e-02, -4.0263e-02, -1.4191e-01,\n",
      "         1.7055e-02,  3.7130e-02,  5.5018e-02, -8.7903e-02, -5.6453e-02,\n",
      "         2.4662e-02, -5.0982e-02, -3.7701e-02,  2.3998e-02, -1.6569e-02,\n",
      "        -2.0854e-02,  3.6549e-02,  9.1622e-02,  6.1644e-02,  2.4988e-02,\n",
      "         8.6914e-02,  1.3393e-02,  4.7371e-02, -5.0397e-02]), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "commits_dataset_train = commits_dataset(X=data_train,y=labels_train)\n",
    "commits_dataset_test = commits_dataset(X=data_test,y=labels_test)\n",
    "print(commits_dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=commits_dataset_train, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=commits_dataset_test, batch_size=32, shuffle=False)\n",
    "#dls = DataLoaders(train_loader,valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionDB[\"is_valid\"] = np.zeros(len(predictionDB))\n",
    "#for i in range(len(predictionDB[\"is_valid\"])):\n",
    "#    predictionDB[\"is_valid\"][i] = 1 if random.random()<0.2 else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from fastai.text.all import *\n",
    "#dls = TextDataLoaders.from_df(predictionDB, text_col='COMMIT_MESSAGE', label_col='inc_complexity', valid_col='is_valid')\n",
    "#dls.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer perceptron\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(384, 1024, bias=True) \n",
    "        self.lin2 = nn.Linear(1024, 120, bias=True)\n",
    "        self.lin3 = nn.Linear(120, 1, bias=True)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        x = xb.float()\n",
    "        #x = xb.view(250, -1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp_learner = Learner(data=data, model=MultilayerPerceptron(), loss_func=nn.CrossEntropyLoss(),metrics=accuracy)\n",
    "#mlp_learner.fine_tune(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (lin1): Linear(in_features=384, out_features=1024, bias=True)\n",
      "  (lin2): Linear(in_features=1024, out_features=120, bias=True)\n",
      "  (lin3): Linear(in_features=120, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MultilayerPerceptron()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/elias/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "1569it [00:09, 159.89it/s]/home/elias/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([29])) that is different to the input size (torch.Size([29, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "1573it [00:09, 161.44it/s]\n",
      "/home/elias/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "15it [00:00, 149.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train loss : 265371.8512, valid loss : 229812.7388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 146.17it/s]\n",
      "15it [00:00, 145.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2, train loss : 265343.3577, valid loss : 229808.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 147.45it/s]\n",
      "14it [00:00, 139.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3, train loss : 265339.9977, valid loss : 229803.5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 149.09it/s]\n",
      "15it [00:00, 143.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4, train loss : 265687.3528, valid loss : 229799.4076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 150.86it/s]\n",
      "15it [00:00, 147.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5, train loss : 265346.0267, valid loss : 229799.8199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 148.11it/s]\n",
      "15it [00:00, 142.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6, train loss : 265339.8897, valid loss : 229801.3490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 151.03it/s]\n",
      "15it [00:00, 145.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7, train loss : 265337.8063, valid loss : 229802.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 148.36it/s]\n",
      "15it [00:00, 144.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8, train loss : 265338.6856, valid loss : 229801.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 143.53it/s]\n",
      "14it [00:00, 136.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9, train loss : 265339.4191, valid loss : 229802.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 145.12it/s]\n",
      "15it [00:00, 145.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, train loss : 265337.5127, valid loss : 229799.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 148.74it/s]\n",
      "15it [00:00, 145.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 11, train loss : 265338.9982, valid loss : 229799.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 151.09it/s]\n",
      "15it [00:00, 144.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 12, train loss : 265351.5174, valid loss : 229800.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 150.48it/s]\n",
      "15it [00:00, 146.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 13, train loss : 265341.6575, valid loss : 229800.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 147.12it/s]\n",
      "15it [00:00, 146.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 14, train loss : 265338.2993, valid loss : 229800.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1573it [00:10, 148.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 15, train loss : 265344.9254, valid loss : 229800.0235\n"
     ]
    }
   ],
   "source": [
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for i, (embeddings, labels) in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(embeddings)\n",
    "        loss = loss_fn(outputs.squeeze(0),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "            \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (embeddings, labels) in enumerate(valid_loader):\n",
    "            outputs = model(embeddings)\n",
    "            loss = loss_fn(outputs.squeeze(0), labels)\n",
    "            \n",
    "            valid_losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}'\\\n",
    "         .format(epoch+1, mean_train_losses[-1], mean_valid_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
