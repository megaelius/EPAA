{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA SELECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select the tables that contains the variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"../data/raw/TDD/GIT_COMMITS.csv\"\n",
    "path2 = \"../data/raw/TDD/SONAR_ANALYSIS.csv\"\n",
    "path3 = \"../data/raw/TDD/SONAR_MEASURES.csv\"\n",
    "db_commits = pd.read_csv(path1,lineterminator='\\n')\n",
    "db_analysis = pd.read_csv(path2)\n",
    "db_measures = pd.read_csv(path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, for each table, we select those variables:\n",
    "\n",
    "    · GIT_COMMITS: project id, commit hash, commit message, author and committer date\n",
    "    · SONAR_ANALYSIS: revision and anlysis key\n",
    "    · SONAR_MESURES: analysis key, complexity, violations and development cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_commits = db_commits[[\"PROJECT_ID\", \"COMMIT_HASH\", \"COMMIT_MESSAGE\", \"AUTHOR\",  \"COMMITTER_DATE\"]]\n",
    "db_commits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_analysis = db_analysis[[\"REVISION\", \"ANALYSIS_KEY\"]]\n",
    "db_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_measures = db_measures[[\"analysis_key\", \"complexity\", \"violations\", \"development_cost\"]]\n",
    "db_measures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to clean the tables by deleting the NA only in the sonar_measures table as we want to keep the time consistency when computing the invervals between the selected variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_measures = db_measures[db_measures[\"complexity\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_sonar0 = db_analysis.merge(db_measures, left_on=\"ANALYSIS_KEY\", right_on=\"analysis_key\")\n",
    "db_sonar = db_sonar0.rename(columns = {'REVISION' : 'COMMIT_HASH'})\n",
    "db_sonar = db_sonar[[\"COMMIT_HASH\", \"complexity\", \"violations\", \"development_cost\"]]\n",
    "db_sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_merged = pd.merge(db_commits, db_sonar, how = 'left', on = 'COMMIT_HASH', indicator = True)\n",
    "db_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_merged = db_merged.sort_values(by=[\"PROJECT_ID\",\"COMMITTER_DATE\"]).reset_index()\n",
    "\n",
    "db_merged['inc_complexity'] = float(\"Nan\")\n",
    "db_merged['inc_violations'] = float(\"Nan\")\n",
    "db_merged['inc_development_cost'] = float(\"Nan\")\n",
    "\n",
    "db_merged.append\n",
    "for i in range(1,db_merged.shape[0]):\n",
    "\n",
    "    #first we make sure that both entries are from the same project (if not leave with the Nan value in the increment variable)\n",
    "    if (db_merged['PROJECT_ID'][i] == db_merged['PROJECT_ID'][i-1]):\n",
    "\n",
    "        for inc_variable in [[\"complexity\",'inc_complexity'],[\"violations\", \"inc_violations\"],[\"development_cost\", \"inc_development_cost\"]]:\n",
    "            variable_act = db_merged[inc_variable[0]][i] #value for the variable in the row i\n",
    "            variable_past =  db_merged[inc_variable[0]][i-1] #value for the variable in the row before i\n",
    "            \n",
    "            if pd.notna(variable_act) and pd.notna(variable_past): #both entries available\n",
    "                db_merged[inc_variable[1]][i] = variable_act - variable_past\n",
    "            else:\n",
    "                break\n",
    "\n",
    "db_increases = db_merged[db_merged['inc_complexity'].notna() & db_merged['inc_violations'].notna() & db_merged['inc_development_cost'].notna()]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_db_merged = db_merged.dropna() #we delete al the NAs in the table\n",
    "\n",
    "final_db = clean_db_merged[[\"PROJECT_ID\", \"COMMIT_HASH\", \"COMMIT_MESSAGE\", \"AUTHOR\", \"COMMITTER_DATE\", \"inc_complexity\", \"inc_violations\", \"inc_development_cost\"]]\n",
    "final_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_db.to_csv('../data/processed/predictionDB.csv', index='False') #export!\n",
    "print(final_db.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa216194d2220cd3b43507c607c96101a9de369308da4c42924730dcfd54ec0c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
