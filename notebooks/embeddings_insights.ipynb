{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62917 62917\n"
     ]
    }
   ],
   "source": [
    "predictionDB = pd.read_csv(\"../data/processed/predictionDB.csv\",lineterminator='\\n')\n",
    "\n",
    "embeddings = [None]*len(predictionDB)\n",
    "i=0\n",
    "k=0\n",
    "#for np_name in glob.glob('./../data/processed/embeddings/*.np[yz]'):\n",
    "#    embeddings[i] = np.load(np_name)\n",
    "#    i = i + 1\n",
    "\n",
    "for x in predictionDB[\"COMMIT_HASH\"]:\n",
    "    embeddings[i] = np.load(\"./../data/processed/embeddings2/\"+x+\".npy\")\n",
    "    i = i + 1\n",
    "\n",
    "embeddings\n",
    "print(len(predictionDB),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclean = \\'\\'\\nfor i,s in enumerate(predictionDB[\"COMMIT_MESSAGE\"][3].split()[:-3]):\\n    if i!=0:\\n        clean+= \\' \\'\\n    clean+=s\\nprint(clean)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "clean = ''\n",
    "for i,s in enumerate(predictionDB[\"COMMIT_MESSAGE\"][3].split()[:-3]):\n",
    "    if i!=0:\n",
    "        clean+= ' '\n",
    "    clean+=s\n",
    "print(clean)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clean_column = [None]*len(predictionDB[\"COMMIT_MESSAGE\"])\n",
    "for i in range(len(predictionDB[\"COMMIT_MESSAGE\"])):\n",
    "    clean = ''\n",
    "    for j,s in enumerate(predictionDB[\"COMMIT_MESSAGE\"][i].split()[:-3]):\n",
    "        if j!=0:\n",
    "            clean+= ' '\n",
    "        clean+=s\n",
    "    clean_column[i] = clean\n",
    "    if not len(clean):\n",
    "        clean_column[i] = predictionDB[\"COMMIT_MESSAGE\"]\n",
    "predictionDB[\"CLEAN_CMS\"] = clean_column\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictionDB.to_csv(\"../data/processed/predictionDB2.csv\", index='False') #export!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  653,   654,   655,   656,   657,   658,   659,   660,   735,\n",
       "          736,   737,   740,   741,   744,   766,   808,   810,   811,\n",
       "          813,   814,   836,   843,   844,   845,   846,   879,   964,\n",
       "         8152,  9327,  9617,  9630, 15423, 15749, 15805, 16381, 16389,\n",
       "        16733, 16750, 16878, 17318, 17848, 18497, 20104, 20393, 20699,\n",
       "        22633, 23796, 23800, 25305, 25346, 25379, 25907, 25908, 25909,\n",
       "        27812, 30106, 30681, 32350, 36389, 36731, 36949, 39477, 39478,\n",
       "        39483, 39484, 39486, 39489, 39490, 39535, 39538, 39824, 39825,\n",
       "        39827, 39828, 39837, 39838, 39841, 39842, 39844, 39845, 39956,\n",
       "        40027, 50447, 50679, 50685, 50697, 50711, 50789, 50807, 50809,\n",
       "        50979, 50984, 51127, 51128, 51129, 51130, 51164, 53525, 53547,\n",
       "        53550, 53558, 53560, 53614, 53616, 54619, 55132, 55550, 56592,\n",
       "        56600, 56608, 56727, 56730, 56734, 56736, 56741, 56745, 56746,\n",
       "        56748, 56756, 56790, 56805, 56809, 56817, 56829, 56866, 56872,\n",
       "        56874, 56913, 56914, 56929, 57031, 61143]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = predictionDB[\"CLEAN_CMS\"].to_frame()\n",
    "#np.where(a.applymap(lambda x: x == ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add log info on maven repository indexing'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionDB[\"CLEAN_CMS\"][4355]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = add test PR: MRM-9\n",
      "b = add some more tests PR: MRM-9\n",
      "c = ZOOKEEPER-2172: Cluster crashes when reconfig a new node as a participant\n",
      "\n",
      "Similarity {emb(a),emb(b)} = 0.95\n",
      "Similarity {emb(a),emb(c)} = 0.09\n",
      "Similarity {emb(b),emb(c)} = 0.14\n",
      "_______________________________________________________________________________________\n",
      "\n",
      "a = http://issues.apache.org/bugzilla/show_bug.cgi?id=40577\n",
      "b = http://issues.apache.org/bugzilla/show_bug.cgi?id=39695\n",
      "c = [MRM-1578] add layout\n",
      "\n",
      "Similarity {emb(a),emb(b)} = 1.00\n",
      "Similarity {emb(a),emb(c)} = 0.13\n",
      "Similarity {emb(b),emb(c)} = 0.13\n"
     ]
    }
   ],
   "source": [
    "a = predictionDB[\"CLEAN_CMS\"][2]\n",
    "b = predictionDB[\"CLEAN_CMS\"][3]\n",
    "c = predictionDB[\"CLEAN_CMS\"][62912]\n",
    "emb_a = embeddings[2]\n",
    "emb_b = embeddings[3]\n",
    "emb_c = embeddings[62912]\n",
    "print(\"a =\",a)\n",
    "print(\"b =\",b)\n",
    "print(\"c =\",c[:73])\n",
    "print(\"\")\n",
    "print(\"Similarity {emb(a),emb(b)} = %.2f\" % (1-spatial.distance.cosine(emb_a, emb_b)))\n",
    "print(\"Similarity {emb(a),emb(c)} = %.2f\" % (1-spatial.distance.cosine(emb_a, emb_c)))\n",
    "print(\"Similarity {emb(b),emb(c)} = %.2f\" % (1-spatial.distance.cosine(emb_b, emb_c)))\n",
    "\n",
    "print(\"_______________________________________________________________________________________\")\n",
    "print(\"\")\n",
    "\n",
    "a = predictionDB[\"CLEAN_CMS\"][6788]\n",
    "b = predictionDB[\"CLEAN_CMS\"][6787]\n",
    "c = predictionDB[\"CLEAN_CMS\"][4444]\n",
    "emb_a = embeddings[6788]\n",
    "emb_b = embeddings[6787]\n",
    "emb_c = embeddings[4444]\n",
    "\n",
    "print(\"a =\",a)\n",
    "print(\"b =\",b)\n",
    "print(\"c =\",c)\n",
    "print(\"\")\n",
    "print(\"Similarity {emb(a),emb(b)} = %.2f\" % (1-spatial.distance.cosine(emb_a, emb_b)))\n",
    "print(\"Similarity {emb(a),emb(c)} = %.2f\" % (1-spatial.distance.cosine(emb_a, emb_c)))\n",
    "print(\"Similarity {emb(b),emb(c)} = %.2f\" % (1-spatial.distance.cosine(emb_b, emb_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit msg a = http://issues.apache.org/bugzilla/show_bug.cgi?id=40577\n",
      "Commit msg b = http://issues.apache.org/bugzilla/show_bug.cgi?id=39695\n",
      "Commit msg c = [MRM-1578] add layout\n",
      "\n",
      "Cosine similarity (a,b) =  0.9983712434768677\n",
      "Cosine similarity (a,c) =  0.13024194538593292\n",
      "Cosine similarity (b,c) =  0.13068857789039612\n"
     ]
    }
   ],
   "source": [
    "a = predictionDB[\"CLEAN_CMS\"][6788]\n",
    "b = predictionDB[\"CLEAN_CMS\"][6787]\n",
    "c = predictionDB[\"CLEAN_CMS\"][4444]\n",
    "emb_a = embeddings[6788]\n",
    "emb_b = embeddings[6787]\n",
    "emb_c = embeddings[4444]\n",
    "print(\"Commit msg a =\",a)\n",
    "print(\"Commit msg b =\",b)\n",
    "print(\"Commit msg c =\",c)\n",
    "print(\"\")\n",
    "print(\"Cosine similarity (a,b) = \",1-spatial.distance.cosine(emb_a, emb_b))\n",
    "print(\"Cosine similarity (a,c) = \",1-spatial.distance.cosine(emb_a, emb_c))\n",
    "print(\"Cosine similarity (b,c) = \",1-spatial.distance.cosine(emb_b, emb_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867696702480316\n"
     ]
    }
   ],
   "source": [
    "print(spatial.distance.cosine(emb_a, emb_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.04031309, -0.06636557, -0.051734935, 0.024...\n",
       "1        [-0.03422957, -0.06418772, -0.04951831, 0.0361...\n",
       "2        [-0.02127257, -0.0677829, -0.050998665, 0.0245...\n",
       "3        [-0.030376969, -0.06409717, -0.03432051, 0.034...\n",
       "4        [-0.06506152, -0.045885205, -0.053898133, 0.03...\n",
       "                               ...                        \n",
       "62912    [0.012309925, -0.03879959, -0.0022678305, 0.06...\n",
       "62913    [-0.02502151, -0.017792063, -0.027390199, 0.00...\n",
       "62914    [-0.034420438, 0.014770305, -0.03304358, 0.047...\n",
       "62915    [-0.061842874, 0.05742638, 0.038782373, -0.034...\n",
       "62916    [-0.025216602, 0.0053232913, 0.03906781, 0.020...\n",
       "Length: 62917, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2 = pd.Series( (v for v in embeddings) )\n",
    "embeddings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "62912    1.0\n",
       "62913    0.0\n",
       "62914    0.0\n",
       "62915    0.0\n",
       "62916    1.0\n",
       "Name: inc_complexity, Length: 62917, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = embeddings\n",
    "labels = predictionDB[\"inc_complexity\"]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i]<=0:\n",
    "        labels[i]=0\n",
    "    else:\n",
    "        labels[i]=1\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(embeddings2, labels, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50333,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commits_dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(self.X.iloc[index]),torch.as_tensor(self.y.iloc[index]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "commits_dataset_train = commits_dataset(X=data_train,y=labels_train)\n",
    "commits_dataset_test = commits_dataset(X=data_test,y=labels_test)\n",
    "# print(commits_dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=commits_dataset_train, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=commits_dataset_test, batch_size=32, shuffle=False)\n",
    "#dls = DataLoaders(train_loader,valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionDB[\"is_valid\"] = np.zeros(len(predictionDB))\n",
    "#for i in range(len(predictionDB[\"is_valid\"])):\n",
    "#    predictionDB[\"is_valid\"][i] = 1 if random.random()<0.2 else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from fastai.text.all import *\n",
    "#dls = TextDataLoaders.from_df(predictionDB, text_col='COMMIT_MESSAGE', label_col='inc_complexity', valid_col='is_valid')\n",
    "#dls.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer perceptron\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(384, 512, bias=True) \n",
    "        self.lin2 = nn.Linear(512, 256, bias=True)\n",
    "        self.lin3 = nn.Linear(256, 1, bias=True)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        x = xb.float()\n",
    "        #x = xb.view(250, -1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp_learner = Learner(data=data, model=MultilayerPerceptron(), loss_func=nn.CrossEntropyLoss(),metrics=accuracy)\n",
    "#mlp_learner.fine_tune(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (lin1): Linear(in_features=384, out_features=512, bias=True)\n",
      "  (lin2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (lin3): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MultilayerPerceptron()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x12288 and 384x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-87f102979056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-78dbde5b23cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x12288 and 384x512)"
     ]
    }
   ],
   "source": [
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for i, (embeddings, labels) in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(embeddings)\n",
    "        loss = loss_fn(outputs.squeeze(0),labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "            \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (embeddings, labels) in enumerate(valid_loader):\n",
    "            outputs = model(embeddings)\n",
    "            loss = loss_fn(outputs.squeeze(0), labels)\n",
    "            \n",
    "            valid_losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}'\\\n",
    "         .format(epoch+1, mean_train_losses[-1], mean_valid_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
